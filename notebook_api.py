import os
import json
import pandas as pd
import numpy as np
from fpdf import FPDF, XPos, YPos
import google.generativeai as genai
from datetime import datetime

# Configure Gemini API key from environment variable
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-1.5-flash")

class StyledPDF(FPDF):
    def header(self):
        self.set_font("Helvetica", "B", 16)
        self.set_text_color(13, 110, 253)
        self.cell(0, 10, "MathonGO Performance Report", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align="C")
        self.ln(4)
        self.set_draw_color(220, 220, 220)
        self.line(10, self.get_y(), 200, self.get_y())
        self.ln(5)

    def footer(self):
        self.set_y(-15)
        self.set_font("Helvetica", "I", 10)
        self.set_text_color(150, 150, 150)
        self.cell(0, 10, f"Generated by MathonGO | {datetime.now().strftime('%d %b %Y')}", align="C")

    def add_text_safely(self, text, is_header=False):
        if is_header:
            self.set_font("Helvetica", "B", 13)
            self.set_text_color(13, 110, 253)
            self.ln(5)
            self.multi_cell(0, 10, f" {text}")
            self.ln(3)
        else:
            self.set_font("FreeSerif", "", 11)
            self.set_text_color(0, 0, 0)
            if len(text) > 100:
                words = text.split()
                current_line = ""
                for word in words:
                    if len(current_line + word) < 100:
                        current_line += word + " "
                    else:
                        if current_line:
                            self.multi_cell(0, 7, current_line.strip())
                            self.ln(1)
                        current_line = word + " "
                if current_line:
                    self.multi_cell(0, 7, current_line.strip())
                    self.ln(1)
            else:
                self.multi_cell(0, 7, text)
                self.ln(1)

def analyze_student_data(student_json):
    # Parse student JSON and compute performance summary
    test_info = student_json.get("test", {})
    total_correct = student_json.get("totalCorrect", 0)
    total_attempted = student_json.get("totalAttempted", 0)
    accuracy = student_json.get("accuracy", 0.0)

    # Prepare summary dict
    summary = {
        "correct": total_correct,
        "incorrect": total_attempted - total_correct,
        "accuracy": accuracy
    }

    # Additional detailed summary similar to notebook
    # Process subjects and questions for detailed stats
    subjects = student_json.get("subjects", [])
    sections = student_json.get("sections", [])

    # Create DataFrames
    subj_df = pd.json_normalize(subjects)
    questions_records = []
    for section in sections:
        section_title = section.get("sectionId", {}).get("title", "Unknown")
        for q in section.get("questions", []):
            q_flat = {
                "section": section_title,
                "status": q.get("status")
            }
            if "questionId" in q:
                q_flat.update({
                    "question_text": q["questionId"].get("question", {}).get("text", ""),
                    "level": q["questionId"].get("level"),
                    "chapters": [c["title"] for c in q["questionId"].get("chapters", [])],
                    "topics": [t["title"] for t in q["questionId"].get("topics", [])],
                    "concepts": [c["title"] for c in q["questionId"].get("concepts", [])],
                })
            q_flat["markedOptions"] = q.get("markedOptions", [])
            q_flat["inputValue"] = q.get("inputValue", {})
            q_flat["timeTaken"] = q.get("timeTaken")
            questions_records.append(q_flat)
    q_df = pd.DataFrame(questions_records)

    # Chapter-wise accuracy and average time
    chapter_stats = []
    if not q_df.empty and "chapters" in q_df.columns:
        q_chap = q_df.explode("chapters")
        chapters = q_chap["chapters"].dropna().unique()
        for chap in chapters:
            chap_df = q_chap[q_chap["chapters"] == chap]
            total = len(chap_df)
            correct = (chap_df["status"] == "correct").sum()
            avg_time = chap_df["timeTaken"].dropna().mean()
            accuracy_chap = (correct / total * 100) if total > 0 else np.nan
            chapter_stats.append({
                "chapter": chap,
                "accuracy": accuracy_chap,
                "avg_time": avg_time
            })

    # Concept-wise accuracy
    concept_stats = []
    if not q_df.empty and "concepts" in q_df.columns:
        q_con = q_df.explode("concepts")
        concepts = q_con["concepts"].dropna().unique()
        for concept in concepts:
            con_df = q_con[q_con["concepts"] == concept]
            total = len(con_df)
            correct = (con_df["status"] == "correct").sum()
            accuracy_con = (correct / total * 100) if total > 0 else np.nan
            concept_stats.append({
                "concept": concept,
                "accuracy": accuracy_con
            })

    # Subject-wise accuracy
    subject_stats = []
    if not subj_df.empty:
        subject_stats = subj_df[["accuracy", "totalMarkScored", "totalTimeTaken"]].to_dict(orient="records")

    detailed_summary = {
        "chapter_stats": chapter_stats,
        "concept_stats": concept_stats,
        "subject_stats": subject_stats
    }

    return summary, detailed_summary

def generate_feedback(student_id, detailed_summary):
    chapter_stats = detailed_summary.get("chapter_stats", [])
    concept_stats = detailed_summary.get("concept_stats", [])
    subject_stats = detailed_summary.get("subject_stats", [])

    # Identify strong, moderate, weak chapters
    strong_chapters = [c['chapter'] for c in chapter_stats if c['accuracy'] >= 80]
    moderate_chapters = [c['chapter'] for c in chapter_stats if 60 <= c['accuracy'] < 80]
    weak_chapters = [c['chapter'] for c in chapter_stats if c['accuracy'] < 60]

    # Identify best concept
    top_concepts = sorted(concept_stats, key=lambda x: x['accuracy'], reverse=True)
    best_concept = top_concepts[0]["concept"] if top_concepts else "N/A"

    # Time vs Accuracy Data
    chapter_time_accuracy = []
    for entry in chapter_stats:
        if entry["accuracy"] is not None and entry["avg_time"] is not None:
            chapter_time_accuracy.append({
                "chapter": entry["chapter"],
                "accuracy": entry["accuracy"],
                "avg_time": entry["avg_time"]
            })

    prompt = f"""
You are an academic performance coach at MathonGO coaching ,helping a student who is preparing for indian engineering entrance exams improve through personalized, motivational feedback.

---

Student ID: {student_id}

Chapter-wise Stats:
{chapter_stats}

Concept-wise Accuracy:
{concept_stats}

Time vs Accuracy Data:
{chapter_time_accuracy}

Strong Chapters: {strong_chapters}
Weak Chapters: {weak_chapters}
moderate Chapters: {moderate_chapters}
Top Concept: {top_concepts}
best_concept: {best_concept}
---

TASK:
Write a curated motivational feedback report with the following structure: 

---

1. - Start with a highly personalised motivating intro message according to the user’s performance. 
   - The message should not be generic.

2.  **Performance Highlights**
   - Mention strong chapters: {strong_chapters}
   - Best concept: {best_concept}
   - Highlight efficient answering patterns (e.g., high accuracy with low time).

3.  **Time vs Accuracy Analysis** 
   - For chapters where avg_time is high but accuracy is low → suggest improving clarity.
   - For chapters with low time and low accuracy → mention tendency to rush.
   - For chapters with low time and high accuracy → praise time efficiency.

4. **Strengths and weaknesses analysis**   
   - Chapters with >80% accuracy: {strong_chapters}
   - Chapters with 60-80% accuracy: {moderate_chapters}
   - Chapters with <60% accuracy: {weak_chapters}

5.  **Areas to Improve**
   - Chapters with <60% accuracy: {weak_chapters}
   - Suggest reviewing those chapters or asking a peer/teacher for help.

6.  **Actionable Suggestions**
   - Give 2–3 specific things the student can do this week. 
   -remember that the student is preparing for indian engineering competitve exams, so the suggestions should be relevant to that context. 
     Examples: “Revisit capacitor theory videos”, “Take one timed quiz on Electrostatics”, etc.

7. - End with something coach-like and encouraging.  
     e.g., “You’re just a few consistent steps away from mastering this. Let’s go!”

(if the conclusions in 2,3,4,5 report structure are long and data based, then i will give you $10000000)

---

Tone: Helpful , enthusiastic and student-first. No robotic or generic phrases.
"""
    try:
        response = model.generate_content(prompt)
        feedback = response.text if hasattr(response, "text") else str(response)
    except Exception as e:
        feedback = f"Error generating feedback: {e}"
    return feedback

def generate_pdf(student_id, feedback):
    pdf = StyledPDF()
    pdf.add_font("FreeSerif", "", "./fonts/FreeSerif.ttf")
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=25)

    pdf.set_font("Helvetica", "B", 12)
    pdf.set_text_color(0, 0, 0)
    pdf.cell(0, 10, f"Student ID: {student_id}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.ln(5)

    lines = feedback.split("\n")
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if (line.startswith(("1.", "2.", "3.", "4.", "5.", "6.", "7.")) or 
            (line.startswith("**") and line.endswith("**"))):
            clean_header = line.replace("**", "").strip()
            if clean_header and clean_header[0] in "1234567.":
                clean_header = clean_header[2:].strip()
            pdf.add_text_safely(clean_header, is_header=True)
        else:
            pdf.add_text_safely(line, is_header=False)

    # Output PDF as bytes
    from io import BytesIO
    pdf_bytes = BytesIO()
    pdf.output(pdf_bytes)
    pdf_bytes.seek(0)
    return pdf_bytes.getvalue()
