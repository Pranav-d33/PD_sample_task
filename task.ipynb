{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53a0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Project\\Sample task\\myenv\\Lib\\site-packages\\fpdf\\__init__.py:40: UserWarning: You have both PyFPDF & fpdf2 installed. Both packages cannot be installed at the same time as they share the same module namespace. To only keep fpdf2, run: pip uninstall --yes pypdf && pip install --upgrade fpdf2\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\Project\\Sample task\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fpdf import FPDF, XPos, YPos\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70863a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-pro', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000027AAA983950>, default_metadata=())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading environment variables from .env file\n",
    "load_dotenv()\n",
    "import os\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a6410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for students: ['sample_submission_analysis_1', 'sample_submission_analysis_2', 'sample_submission_analysis_3', 'sample_submission_analysis_4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_path = \"./data\"\n",
    "\n",
    "# Dictionaries to hold each student's data\n",
    "test_infos = {}\n",
    "overall_stats = {}\n",
    "subjects_dfs = {}\n",
    "questions_dfs = {}\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".json\"):\n",
    "        student_id = file.split(\".\")[0]\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)[0]  # Each file is a list with one dict\n",
    "\n",
    "        # Test-level info\n",
    "        test_infos[student_id] = data[\"test\"]\n",
    "        overall_stats[student_id] = {\n",
    "            \"totalTimeTaken\": data.get(\"totalTimeTaken\"),\n",
    "            \"totalMarkScored\": data.get(\"totalMarkScored\"),\n",
    "            \"totalAttempted\": data.get(\"totalAttempted\"),\n",
    "            \"totalCorrect\": data.get(\"totalCorrect\"),\n",
    "            \"accuracy\": data.get(\"accuracy\")\n",
    "        }\n",
    "\n",
    "        # Subjects DataFrame\n",
    "        subjects_dfs[student_id] = pd.json_normalize(data[\"subjects\"])\n",
    "\n",
    "        # Questions DataFrame\n",
    "        questions_records = []\n",
    "        for section in data.get(\"sections\", []):\n",
    "            section_title = section[\"sectionId\"].get(\"title\", \"Unknown\")\n",
    "            for q in section.get(\"questions\", []):\n",
    "                q_flat = {\n",
    "                    \"section\": section_title,\n",
    "                    \"status\": q.get(\"status\")\n",
    "                }\n",
    "                \n",
    "                if \"questionId\" in q:\n",
    "                    q_flat.update({\n",
    "                        \"question_text\": q[\"questionId\"][\"question\"].get(\"text\", \"\"),\n",
    "                        \"level\": q[\"questionId\"].get(\"level\"),\n",
    "                        \"chapters\": [c[\"title\"] for c in q[\"questionId\"].get(\"chapters\", [])],\n",
    "                        \"topics\": [t[\"title\"] for t in q[\"questionId\"].get(\"topics\", [])],\n",
    "                        \"concepts\": [c[\"title\"] for c in q[\"questionId\"].get(\"concepts\", [])],\n",
    "                    })\n",
    "                q_flat[\"markedOptions\"] = q.get(\"markedOptions\", [])\n",
    "                q_flat[\"inputValue\"] = q.get(\"inputValue\", {})\n",
    "                q_flat[\"timeTaken\"] = q.get(\"timeTaken\")\n",
    "                questions_records.append(q_flat)\n",
    "        questions_dfs[student_id] = pd.DataFrame(questions_records)\n",
    "\n",
    "print(\"Loaded data for students:\", list(test_infos.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc7f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionaries for storing each student's summaries for prompting\n",
    "student_summaries = {}\n",
    "\n",
    "for student_id in test_infos:\n",
    "    summary = {}\n",
    "    subj_df = subjects_dfs[student_id]\n",
    "    q_df = questions_dfs[student_id]\n",
    "    \n",
    "    # --- Chapter-wise accuracy and average time ---\n",
    "    chapter_stats = []\n",
    "    if not q_df.empty and \"chapters\" in q_df.columns:\n",
    "        # Explore chapters for per-chapter stats\n",
    "        q_chap = q_df.explode(\"chapters\")\n",
    "        chapters = q_chap[\"chapters\"].dropna().unique()\n",
    "        for chap in chapters:\n",
    "            chap_df = q_chap[q_chap[\"chapters\"] == chap]\n",
    "            total = len(chap_df)\n",
    "            correct = (chap_df[\"status\"] == \"correct\").sum()\n",
    "            avg_time = chap_df[\"timeTaken\"].dropna().mean()\n",
    "            accuracy = (correct / total * 100) if total > 0 else np.nan\n",
    "            chapter_stats.append({\n",
    "                \"chapter\": chap,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"avg_time\": avg_time\n",
    "            })\n",
    "    summary[\"chapter_stats\"] = chapter_stats\n",
    "\n",
    "     # time vs accuracy per chapter\n",
    "    chapter_time_accuracy = []\n",
    "    for entry in chapter_stats:\n",
    "      if entry[\"accuracy\"] is not None and entry[\"avg_time\"] is not None:\n",
    "        chapter_time_accuracy.append({\n",
    "            \"chapter\": entry[\"chapter\"],\n",
    "            \"accuracy\": entry[\"accuracy\"],\n",
    "            \"avg_time\": entry[\"avg_time\"]\n",
    "        })\n",
    "    summary[\"time_accuracy\"] = chapter_time_accuracy\n",
    "\n",
    "\n",
    "    # --- Concept-wise accuracy ---\n",
    "    concept_stats = []\n",
    "    if not q_df.empty and \"concepts\" in q_df.columns:\n",
    "        q_con = q_df.explode(\"concepts\")\n",
    "        concepts = q_con[\"concepts\"].dropna().unique()\n",
    "        for concept in concepts:\n",
    "            con_df = q_con[q_con[\"concepts\"] == concept]\n",
    "            total = len(con_df)\n",
    "            correct = (con_df[\"status\"] == \"correct\").sum()\n",
    "            accuracy = (correct / total * 100) if total > 0 else np.nan\n",
    "            concept_stats.append({\n",
    "                \"concept\": concept,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "    summary[\"concept_stats\"] = concept_stats\n",
    "\n",
    "    # --- Subject-wise accuracy ---\n",
    "    if not subj_df.empty:\n",
    "        summary[\"subject_stats\"] = subj_df[[\"accuracy\", \"totalMarkScored\", \"totalTimeTaken\"]].to_dict(orient=\"records\")\n",
    "    else:\n",
    "        summary[\"subject_stats\"] = []\n",
    "\n",
    "    # Store for prompting\n",
    "    student_summaries[student_id] = summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae39c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7006ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:27<00:00,  6.86s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Configure Gemini API\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "# Dictionaries to hold feedback per students\n",
    "student_feedback = {}\n",
    "\n",
    "for student_id in tqdm(student_summaries.keys()):\n",
    "    summary = student_summaries[student_id]\n",
    "    \n",
    "    \n",
    "    def generate_prompt(student_id, summary):\n",
    "       \n",
    "       chapter_stats = summary.get(\"chapter_stats\", [])\n",
    "       concept_stats = summary.get(\"concept_stats\", [])\n",
    "       subject_stats = summary.get(\"subject_stats\", [])\n",
    "       time_accuracy = summary.get(\"time_accuracy\", [])\n",
    "\n",
    "    # Identify strong & weak chapters\n",
    "    strong_chapters = [c['chapter'] for c in chapter_stats if c['accuracy'] >= 80]\n",
    "    moderate_chapters = [c['chapter'] for c in chapter_stats if c['accuracy'] <= 80 and c['accuracy'] >= 60]\n",
    "    weak_chapters = [c['chapter'] for c in chapter_stats if c['accuracy'] < 60]\n",
    "\n",
    "    # Identify best concept\n",
    "    top_concepts = sorted(concept_stats, key=lambda x: x['accuracy'], reverse=True)\n",
    "    best_concept = top_concepts[0][\"concept\"] if top_concepts else \"N/A\"\n",
    "\n",
    "\n",
    "\n",
    "    # Building prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an academic performance coach at MathonGO coaching ,helping studenta who is preparing for indian engineering entrance exams improve, through personalized, motivational feedback.\n",
    "\n",
    "---\n",
    "Student ID: {student_id}\n",
    "\n",
    "Chapter-wise Stats:\n",
    "{chapter_stats}\n",
    "\n",
    "Concept-wise Accuracy:\n",
    "{concept_stats}\n",
    "\n",
    "Time vs Accuracy Data:\n",
    "{chapter_time_accuracy}\n",
    "\n",
    "Strong Chapters: {strong_chapters}\n",
    "Weak Chapters: {weak_chapters}\n",
    "moderate Chapters: {moderate_chapters}\n",
    "Top Concept: {top_concepts}\n",
    "best_concept: {best_concept}\n",
    "---\n",
    "\n",
    "TASK:\n",
    "Write a curated motivational feedback report with the following structure: \n",
    "\n",
    "---\n",
    "\n",
    "1. - Start with a highly personalised motivating intro message according to the user’s performance. \n",
    "   - The message should not be generic.\n",
    "\n",
    "   \n",
    "2.  **Performance Highlights**\n",
    "   - Mention strong chapters: {strong_chapters}\n",
    "   - Best concept: {best_concept}\n",
    "   - Highlight efficient answering patterns (e.g., high accuracy with low time).\n",
    "\n",
    "   \n",
    "3.  **Time vs Accuracy Analysis** \n",
    "   - For chapters where avg_time is high but accuracy is low → suggest improving clarity.\n",
    "   - For chapters with low time and low accuracy → mention tendency to rush.\n",
    "   - For chapters with low time and high accuracy → praise time efficiency.\n",
    "\n",
    "   \n",
    "4. **Strengths and weaknesses analysis**   \n",
    "   - Chapters with >80% accuracy: {strong_chapters}\n",
    "   - Chapters with 60-80% accuracy: {moderate_chapters}\n",
    "   - Chapters with <60% accuracy: {weak_chapters}\n",
    "\n",
    "   \n",
    "5.  **Areas to Improve**\n",
    "   - Chapters with <60% accuracy: {weak_chapters}\n",
    "   - Suggest reviewing those chapters or asking a peer/teacher for help.\n",
    "\n",
    "   \n",
    "6.  **Actionable Suggestions**\n",
    "   - Give 2–3 things the student can do this week. \n",
    "   - Remember that the student is preparing for indian engineering competitve exams, so the suggestions should be relevant to that context. \n",
    "\n",
    "     \n",
    "7. - End with something coach-like and encouraging.  \n",
    "     e.g., “You’re just a few consistent steps away from mastering this. Let’s go!”\n",
    "\n",
    "(if the conclusions in 2,3,4,5 report structure are long and data based, then i will give you $10000000)\n",
    "---\n",
    "\n",
    "Tone: Helpful , enthusiastic and student-first. No robotic or generic phrases.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        feedback = response.text if hasattr(response, \"text\") else str(response)\n",
    "        student_feedback[student_id] = feedback\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {student_id}: {e}\")\n",
    "        student_feedback[student_id] = f\"Error generating feedback: {e}\"\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9d78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StyledPDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Helvetica\", \"B\", 16)\n",
    "        self.set_text_color(13, 110, 253)\n",
    "        self.cell(0, 10, \"MathonGO Performance Report\", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align=\"C\")\n",
    "        self.ln(4)\n",
    "        self.set_draw_color(220, 220, 220)\n",
    "        self.line(10, self.get_y(), 200, self.get_y())\n",
    "        self.ln(5)\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font(\"Helvetica\", \"I\", 10)\n",
    "        self.set_text_color(150, 150, 150)\n",
    "        self.cell(0, 10, f\"Generated by MathonGO | {datetime.now().strftime('%d %b %Y')}\", align=\"C\")\n",
    "\n",
    "    def add_performance_summary(self, student_id, overall_stats):\n",
    "        \"\"\"Add performance summary section\"\"\"\n",
    "        self.set_font(\"Helvetica\", \"B\", 14)\n",
    "        self.set_text_color(13, 110, 253)\n",
    "        self.cell(0, 10, \"Performance Summary\", new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        self.ln(5)\n",
    "        \n",
    "        # Summary box with light background\n",
    "        self.set_fill_color(245, 245, 245)\n",
    "        self.set_font(\"Helvetica\", \"\", 11)\n",
    "        self.set_text_color(0, 0, 0)\n",
    "        \n",
    "        stats = overall_stats.get(student_id, {})\n",
    "        correct = stats.get('totalCorrect', 0)\n",
    "        attempted = stats.get('totalAttempted', 0)\n",
    "        incorrect = attempted - correct if attempted else 0\n",
    "        accuracy = stats.get('accuracy', 0)\n",
    "        \n",
    "        \n",
    "        # Create summary content \n",
    "        summary_text = f\"\"\"\n",
    "Correct Answers: {correct}\n",
    "Incorrect Answers: {incorrect}\n",
    "Total Attempted: {attempted}\n",
    "Accuracy: {accuracy:.1f}%\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.multi_cell(0, 6, summary_text.strip(), fill=True)\n",
    "        self.ln(8)\n",
    "\n",
    "    def add_text_safely(self, text, is_header=False):\n",
    "        \"\"\"Add text with proper line wrapping and spacing\"\"\"\n",
    "\n",
    "        clean_text = text.replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"\"\", '\"').replace(\"\"\", '\"').replace(\"'\", \"'\").replace(\"'\", \"'\")\n",
    "\n",
    "\n",
    "        if is_header:\n",
    "            self.set_font(\"Helvetica\", \"B\", 13)\n",
    "            self.set_text_color(13, 110, 253)\n",
    "            self.ln(5)\n",
    "            # Change from cell() to multi_cell() to prevent spillover\n",
    "            self.multi_cell(0, 10, f\" {clean_text}\")\n",
    "            self.ln(3)\n",
    "        else:\n",
    "            self.set_font(\"FreeSerif\", \"\", 11)\n",
    "            self.set_text_color(0, 0, 0)\n",
    "            \n",
    "            # Split long text into chunks\n",
    "            if len(text) > 100:\n",
    "                words = text.split()\n",
    "                current_line = \"\"\n",
    "                for word in words:\n",
    "                    if len(current_line + word) < 100:\n",
    "                        current_line += word + \" \"\n",
    "                    else:\n",
    "                        if current_line:\n",
    "                            self.multi_cell(0, 7, current_line.strip())\n",
    "                            self.ln(1)\n",
    "                        current_line = word + \" \"\n",
    "                if current_line:\n",
    "                    self.multi_cell(0, 7, current_line.strip())\n",
    "                    self.ln(1)\n",
    "            else:\n",
    "                self.multi_cell(0, 7, text)\n",
    "                self.ln(1)\n",
    "\n",
    "# Generate styled PDFs\n",
    "output_folder = \"./reports\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for student_id, feedback in student_feedback.items():\n",
    "    try:\n",
    "        pdf = StyledPDF()\n",
    "        \n",
    "        # Load font before adding page\n",
    "        pdf.add_font(\"FreeSerif\", \"\", \"./fonts/FreeSerif.ttf\")\n",
    "        \n",
    "        pdf.add_page()\n",
    "        pdf.set_auto_page_break(auto=True, margin=25)\n",
    "\n",
    "        # Student header\n",
    "        pdf.set_font(\"Helvetica\", \"B\", 12)\n",
    "        pdf.set_text_color(0, 0, 0)\n",
    "        pdf.cell(0, 10, f\"Student ID: {student_id}\",new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.ln(5)\n",
    "\n",
    "        # Add performance summary at the beginning\n",
    "        pdf.add_performance_summary(student_id, overall_stats)\n",
    "\n",
    "        # Process feedback line by line with better logic\n",
    "        lines = feedback.split(\"\\n\")\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Check if it's a header (starts with number or **text**)\n",
    "            if (line.startswith((\"1.\", \"2.\", \"3.\", \"4.\", \"5.\", \"6.\", \"7.\")) or \n",
    "                (line.startswith(\"**\") and line.endswith(\"**\"))):\n",
    "                \n",
    "                # Clean the header text\n",
    "                clean_header = line.replace(\"**\", \"\").strip()\n",
    "                if clean_header.startswith(tuple(\"1234567.\")):\n",
    "                    clean_header = clean_header[2:].strip()  # Remove \"1. \" etc.\n",
    "                \n",
    "                pdf.add_text_safely(clean_header, is_header=True)\n",
    "            else:\n",
    "                # Regular content\n",
    "                if line:\n",
    "                    pdf.add_text_safely(line, is_header=False)\n",
    "\n",
    "        # Save\n",
    "        output_path = os.path.join(output_folder, f\"{student_id}_report.pdf\")\n",
    "        pdf.output(output_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error for {student_id}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
